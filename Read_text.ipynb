{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedDhibi/AI-Based-PMMA-Sheet-Identification-Classification-and-Sorting-Optimization/blob/main/Read_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4cd8417-5b77-442f-97e8-d363f10dfcf1",
      "metadata": {
        "id": "b4cd8417-5b77-442f-97e8-d363f10dfcf1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read CSV file into DataFrame\n",
        "results_df = pd.read_csv('important_text.csv', dtype={'ID': int, 'text': str})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ed1528-8c8f-45e2-bf73-039417994436",
      "metadata": {
        "id": "56ed1528-8c8f-45e2-bf73-039417994436",
        "outputId": "ff065fbc-6f0c-4481-f257-333216dc3678"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Kem Kemmler Kemmlem Kemmler KemmLeR Kemmier Ke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>) - 65 - (</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>482 PLEXIGLASS XT Weiss 7-IX PLEX THE ORIGINA ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>752 12. ~_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Feb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>1071</td>\n",
              "      <td>EEE nes tantleerat faeen ete lenter [ai Fea HH...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>1072</td>\n",
              "      <td>Here Alplaee oxyd Mafat O '93 Eer 3O' EBpl BAb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>1077</td>\n",
              "      <td>Ms JHUU Hf Um : HMpHeTU Shanenenenh 7~&gt; aaeret...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>1098</td>\n",
              "      <td>AI. 7\"? JM ULZ4 : 0LUUSY W5 MET8 M 2o ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>1100</td>\n",
              "      <td>W AZ1L ^  QNANHUN  % A DERA / ; MRMLLEM 412V A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>333 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID                                               text\n",
              "0       0  Kem Kemmler Kemmlem Kemmler KemmLeR Kemmier Ke...\n",
              "1       2                                         ) - 65 - (\n",
              "2       3  482 PLEXIGLASS XT Weiss 7-IX PLEX THE ORIGINA ...\n",
              "3       4                                         752 12. ~_\n",
              "4       5                                                Feb\n",
              "..    ...                                                ...\n",
              "328  1071  EEE nes tantleerat faeen ete lenter [ai Fea HH...\n",
              "329  1072  Here Alplaee oxyd Mafat O '93 Eer 3O' EBpl BAb...\n",
              "330  1077  Ms JHUU Hf Um : HMpHeTU Shanenenenh 7~> aaeret...\n",
              "331  1098            AI. 7\"? JM ULZ4 : 0LUUSY W5 MET8 M 2o ,\n",
              "332  1100     W AZ1L ^  QNANHUN  % A DERA / ; MRMLLEM 412V A\n",
              "\n",
              "[333 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d87f2ec-a855-480f-894c-7f229895e65b",
      "metadata": {
        "id": "0d87f2ec-a855-480f-894c-7f229895e65b",
        "outputId": "4a84b40c-c267-4989-a45c-fe32fcb82377"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['8 8 8 & & 3 8 Jojoxa ext exi exe \\'WuOD\" exa O3M 01* Luoj\" 0meniw 1060 (5u10 Aov un Mw rulinds exe Ohi nuues \\'Uohiyj un 0557 % Letto01ts aajd ill el modalp Jowva Koalaleialn ucudded\" ~OrDeid 67 %o//n? aarn Foeo LeLon enneil adoilow Wcor Sctuqug #\\'nj4mn Adnt ?Vllunll! Insan eaiset antoor aile arqided Asep nep WOD Ane WOj\" Gao MRIN:QT n Wlugal3s acd gEcO Uim 1484 0\" &PmS Mnadenn iog 40) M480J6 Lozulowi TUpj ieid Len Enibo \"\"ikueM F^ Auj u Euts Tac 400{i5 (cun uo) JSUjL 0706 4alrp Jouc0 = F0= MMAt Uqovipo\\' #Guiieo? An Haaa 7ludel Va An ap epeld Rc-A Ox3 exolo oloxa Uoioxa exolon uoloxa exolon exolon exolon Uosxa exolon exolon exolon exolon uoioxa Uoioxa exolon exolon exolon Uoioxa exolon dnojbuojoxaMMM Aeyoubd Quefeuo \"uCVELLOIUI Vouminad dnojbuojoxaMMM #uL O Manntion cpeloulina [ 04tod Eln # exc ~Vazoboma@Rruan tot \"uontotn Ventieidcon 01ro4m? D 08004n?olupd un WUiNOT - VoAO4ino  aisndoto VaMM uaunuao KnituolluuomEISL? LDio 3057 057 - ~nt eujub 7867072 endoT LoJ tun ARE eine Jodain Lilhen = ep-4m UDutuudy Ln 0 Jnq-QLu \\'diuenond 18am i1\" solqo D . tounyp enced \\'IU #uiod = \\'onn IntRutt Du#D erond J7J Meeeed QAnaicd On Kunn 4tna #Gucu? \"Dounnieenco ajpniu \\'0Mtoj oncholen JIeIDn . \\'OJont 660o2 unno OuIn ICJILOL [ ~inu AUd @a (7#d [UOJ #HA4 Rhoa . Lnqi Mjorni \\'uucdUonjjidoc- diabtilom = Uol od eD oMUrtnred [ I\\'Khun . ouiuquad VuJLUDiPOE 45o: Eo I 6ao> sol 0hq5 AjoX OCTiUoUA #lovoc= {i5o 0esior - Uonjd 42p M10 AJudhlo) \"D 0 Eialnj \" #pou Lonc J0qUD 1Jj0 ; altbueuE JuocoaioJ V~0 0JLS 11uo4nn4 JU-RUjUyOOp $ 04ltoug elted [ 0doron euSJ e as FE Oiu#luhseh= F0io +0 Apau] Un? Voll Fodntd Te| | (qlrmiuo oleuoquebllod pnes 5i 1040buoj Wal Uot 2345 Ojudisiso] - L01oai Jual ojadwajul quawalead . \\'Ua#on4d An-Hue = \\'MMM anbeld r\"dnojbuojoxat ojeuoquejAjod E Aalen #0iQ) = dorMjnuidi Deao queisisa4 \\'uounduidzo Ulolo puzluo4j:jo-Anj*W sopjoduuoiui = rdnojbuojoxa MMM eculyjuia n Lobaneenatana abipuaisaquaam eld e triun Ounquauut 708tdrk ounicor^pLn Lnua u 0yxe 164ug2 404p40) Opuduate5 VJi ~po A-ung MMM punon W uo vohtuuoiui \\'yjolov e TSed \\'OMgthino Uo mojbuojoxa  A DueU \"uelitipur e ~LA0 OnGn Mion $ mjnn 1 Huko = Utdudeli Insei #blbuj 4uo #ultios _ 581040J Kalut duopinjo) {ULn Upptluqjuittwfienuoou7 Epejep Fuonpsujo #Ptun 5 Unvp [ ~Dod Motoein joi~ uu Mad Wmar e 641Ll4i5 Vonon * \\'cdtuoh 40 4ioi) E Fpunu Jnr-U\" PLD UoLilio oxoo or\"dun nt AOal {Ulno inL& Gun 0  Lnjioju #uie\\'Duai CTE LP\"TUD) F02s L LuAotnt 04 \"\\'Di0ey Gvcun . @ojed 4a lmnb? tjqia 7ejus0yi duin4 Wjuwn VMp JLUA WUI nud51ar Vangl] Gutnnie Oiico 01 1- # A UPESUPILUS ujuyJo yoikanund . rolenp oun er Qununow ( Junoool [untaanuy ZD uaug {0jney ~Uruucs ieuod \" } OD LDiys oJnoiainoibd U1 E (amnu Md *5 nts . Lofhui Jotinn - TUEa Ludhiua eotnbs POJL Ciurlabunuje0 7 exolon Ja4 Woindly Tond 01  Joohlietpi\"q Iilu EUUT - ILDvmimrao iduily Ooaino 4i0 uolJnli ~6uni4ji4oso0-An = abipugisoqsgunjoiim Loptifiui TLOIDUO} Jo 010bn ` cucminncedaon Wnionsoroud u~ exolon #D? = ouejdieuoquejlOd = MADtelLlEn 9ir187 Gicietaud * IPepis-\"ianop ( huejsisox-Jalieom CU0) {ud 57 Eouodt? Or] (rovotxoipu exolon ojeuoquesAlod: Hionnolrn Jaays = uoisjujoud [ Eoperoque ojeuoquejllod exoloc TuJisisal Placa de ados UV e E sheet con UV coallng: Uojoxa wltn Hon ecu chtung_ Donot &r plico  dilatacion Noioxa Jonan 1 Quenla 51 05 p0 UMci povcap Lnon mounung  Rou eon  aiter Pinll Sed e tent llotnan Pwattal pnd tobl don: anl WWW: Lexolongrou Sttumm nigmib don Laltet? aux com 00tag cotos des $ alle slockuge  Doschont Conslgnos de Lastra in Uatl; Fanioic Uwicur,C\" con Eolnd Ftola stoccaqglo aDo pla dal eaiole Tem( Totl enlcqve Relnlnlna Dc pltnu 5 n e Rollat AndC Uactan pmuo Ntia ura ` alto (ntetne ulu Eco oxa to Nsd Oxa doioxa Jojoxa {ojoxa Jojoxa jojoxa bojoxa Nojoxa dojoxa Uojoxa soioxa resisten pollcarbonato [ ambos protecclon E uoioxa polycarbonate aimagonacaio Mclntplictor ndlettlontido Weather-resistant E No eiponq Liplee  con De L hn cdyhedaon (double-slded ( Polycarbonatplatte CAchn  eh pfotectg fe Wltterungsbestandige E nitructknt \\'Onc tna to& nttalcldn coname UV-Baschic dect wunupht Anirucclotat beldseltlger E outedo moutue Motec; womhe DUCA shutrfol# Laarun qtquntyalia\" Pltie Fit G2- nanuctiont aned \\'Utics Inie atlon Sten 570â‚¬ Lnc0 mty 1prtoula antot Da cabonuts nsht dor Wutter Eonttn- Atro [ \\'ptoiecton eircund Gete 4ocicu? Duttto cump Jnmtion nruthnng Amm c Uiatc/ Uniay con ejunatheihet Lmnana J0\" Pole  Dorl :Uia WiLob a Dia Con #2u. Filen Detoro Joui \\'LncobE aojcon Juochninq Romo< Kprotccte 4Coninuccon; TToa 0 un ) Ouna QuIn E (ocutnl un olo a ouoin Jnutal cotttot. ertion Tu nunu = dotn & honbo \\'Schuutim brvotSLd4 Cleenind Jhleam Joft LDong , Yahtna utotwin Atn  Informacion Tuni Cncontana conticionardela Gln ntutaln Aen dungimutei Uxnfue iotonbontn tnat uetnicnttn cnamot \\'Outu Lea _p cWas the Vai dURd Ktrointapt \\'Mit Ic ubt and Aand mt nebilto Funef Intatmatloron Kontutn 0dtt Letungutal Mcund oneus Mich nundjrichus condiionicin Da 08t Gonuindr Aet Khre cunwniy (wnreitung tOtl0 otiturn 5 0 com lexolongroups MAnMcndund Wsotie Wcerbestendlge E Unformuattonen mur hltta WWW: eninelmn met UV-bescheren Intemperles Garantiabedndunaan resistante Lexolongroup: polycarbonate [ lnttrueiivoor dcur WWWA( Plaque \"Dofluon anti-UV: Intemperle revetement hlcotte o Lavec tovn resistante ducu for\"chl policarbonato #ccionmm Dujut antrambi GDodu thurtecte oatmon rlvestlmento E Intrctiet Tilon_ Brabr Mid4 4 UU (oyonnca Jn Drototin0 htruxodledlo Lattra coni L Anqua On pOnc # Donita ~Gobnj E xoott 70n1a0o Nimorenc ctturnadtto 0 Ga Conto 4d J intemocle #htjton  \\'comote 0 #carcnc\"Du Toptonfi ~latnsn: /Drty i montn phci  1203\\' foLi Hartet DofeclionGvani dacha npotadoto roteclor Umortoglo \"Eca |Jutro Wirubloni pet Enau o Oebdrob lno coNd ~Reld Dut UnC nrutro, (nonuono \\'dctergent Liino OUun Ccoo Jvtt Un (cponge eOUtr Un chilton &  iubto 0neid yo ulstra 4alto 09\" atesu lieut UQIAC Lover @da Tnpolerino ptl Uuklh Un\" cu CEe Knottt polntus md4 soint Onuot ccnon;0 nnitro; 65|0 Uelenttt Drju 0 \\'Jonlot= Sxa mobda Jeur Cutiaation = Lm\"uter {Ruun? Coltac d) Aentomntlont mmnigiu noto ~Leua Voui [rouv3 02 plutamole \\'conditioni 40 McchoqujiF Con Olnognn 0i â‚¬amo cia alnu Ouonor ent etat) 0 iOkgnti Oobpllque unoonno [ couuan mNl oggetti co eavoruort Lcom Lexolongroup: Untormation4 wuitune +90 contyltorc Inottro WWWa uieton di qjrani \\'cordltoni nonchaiyllg Dxa com Lexolongroup: WWW E Oxa uoioxa OXa exolon uoioxa exolon exolon exolon\" exalon uooxi exolon exolon pioxa exolo exo\"'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df[results_df['ID'] == 15]['text'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20e4ff51-786b-424b-8b6b-c27b6ef419bb",
      "metadata": {
        "id": "20e4ff51-786b-424b-8b6b-c27b6ef419bb",
        "outputId": "1f9dd462-5313-4ac1-bfea-842326594c79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['MI #Hi 8 8 8,5 9 8 9 BC2] !â‚¬2t Service Side (DuB Jop mmananan GAtb Jan | ( nbsni 0i uCMFC 37-o0 b mid\\'MAA #SVnelxaral WHOel onjons UC!D \\' . ` ` Idj) 0i /r Suokm \" .s^tjio mon-o(G.#uE) ICOOE 0s1 Nania 0} Buipjoood @IiAuod ?803 \\'30^ . :^(nn.. , -  . . . _ | {LJOjuo? eubab?y KuDlad Aponsuda HawE Wued40 XidWuapoi} Poranelgore . /y7c JGTuerme TOOWIOa  ^.\\'juc NeNq #NIDI4O BHL (catlpno)1o06 OSHNE hid ouill  - . ^ - ncpold 0i0010e d  Poisubg 4qug (ued IP 040120i0e4 eiyoyou \\' :J0 ka7d 4 _ ` Janiun Pain Kenca inirsui dd3i (ad3) uoppupjpod enpold a3 a^ ] apojb jbuuDI uplbupuogap ahbarnd \"Ejpak OE 01 dn i0 eaiupiong: 2AIL + 0S\\' quup QEp 01zu01ob pun OuDiujol odl} Pp Qpuopas V Sv751737d Pp-noisixeid MMAA @h-ad anan ^. : \"SdAnh?uzJouo ap edig xojd Mmkedioi Que buebDujun  ^ . .e_fOu| {~EzQLosi0} 6uipjojoo {64203) Tooos O5i 4_\" Guixseu I-CeaLosi DUjJOU Di Opuo? 7`0 oujd PJomonpoi Sv |\"; \\' arsine SaSt lelxstd Minal WHQd A8 JVNI5IdO 3HL tocos <\\'\\' \\'^ {6\"` ~ V| , L ^ 66v , \\' < Jmasi\\' io3u5 0SV7bIX:Id (U0min uda u. .. uddop Ve Nvuvnd Rab Da CJ; , I@Ma \"p #D ByxoidAAM SMubixard WHOe] dons PUp uon Juu; \" . Io AAA 0u0vm!& ! OMn PUL mnou A10 ST| !716K4  WVt wwwpe Fortdnf omdrcetorod ROHM PLexiGLKS- plexiglda de D6W554I & 30 vEARS 40 \\'1e GUARANTI dapune  \\' . 0 E Cnironi sheet EpDL nsei PLEXIGLASE 4.|\\' \\' 4 \\'A) DUN ENSO 50001 THE ORIGINAL BY ROHM PMMA PEXMCASs ragistere products Aeriligc <.7 condo la narrna IS0 7873-- marskcing nFNISO SOOO1 (Energy Cost dcrylic occording to \\'50 7023-\\' Inton \\'. ^ 0 Imtagazzinamento amo vryplaxlglaa de 6 \\' naoanoton doto Mee oa PE-LD Mywplexlglaa de PLEXAGLAS eecondu dal tipo Torniama und garanzia di30 anni 30 Years  Wa give guarantee 0f Up tv { yedr: GuaRANEE denandingron matarial grude Uee Enviranmental Product Doclaration (EPD} EPDI Inatitut Bquer und Umiele n | PLEY 0 > \\' Un marohla raglutrata d Ranm Gmbh Darmatadt Ia Gerania predott FHExid Aee sono fepnilcati nnte DIlHLEN4SO 9001 (Qualital THE ORIGINA DINENiso rodpl (Enorglo) e DIN ENISO 14001 Vambiente) = registered (rademark Or Rofr amek Darmstadt; Glermony Aeryliqua contornte ( ` EcCcadnd panpc BnLSO) #oo (Quality), Gcst aaryllc according to DIN EN IS0 5OCOI {En#\\'9/)cof.sCes .\\' .` Untatmatlona curatral Kcmton 3U\"(Jfi and gtorag RROHM (plexiels: WX plexiglog-de Selar Id 30 vears uS(u  |ne Wegiv2 No eltowig der @ntd moule 487 2 H apis aoinuas I31sai JuG 2 2 618 Kol Hue'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter for rows where 'ID' is 20 and select the 'text' column\n",
        "text=results_df[results_df['ID'] == 15]['text'].values\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00262e1c-88b9-472e-b77a-267f4f16d45c",
      "metadata": {
        "id": "00262e1c-88b9-472e-b77a-267f4f16d45c"
      },
      "outputs": [],
      "source": [
        "# Clean the text\n",
        "import re\n",
        "def clean_text(text):\n",
        "    # Convert bytes-like object to string (assuming UTF-8 encoding)\n",
        "    text_str = text.decode('utf-8') if isinstance(text, bytes) else text\n",
        "\n",
        "    # Remove special characters, digits, and punctuation\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text_str)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    cleaned_text = cleaned_text.lower()\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    cleaned_text = ' '.join(cleaned_text.split())\n",
        "\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf3302bb-b8c4-4048-9e0d-f2184f463d66",
      "metadata": {
        "id": "bf3302bb-b8c4-4048-9e0d-f2184f463d66"
      },
      "outputs": [],
      "source": [
        "cleaned_text=clean_text(text[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "326a3b0c-cd50-4a83-94cf-dc1a2e2eb852",
      "metadata": {
        "id": "326a3b0c-cd50-4a83-94cf-dc1a2e2eb852",
        "outputId": "e3cf4f0b-a58d-4103-dc09-6292be5b6e17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\adminsyma\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a374bc-2716-4f93-8c08-eb2fc784bc97",
      "metadata": {
        "id": "a9a374bc-2716-4f93-8c08-eb2fc784bc97"
      },
      "source": [
        "# Pyenchant:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97aaad0f-ac66-410a-bf93-6786407a1f0e",
      "metadata": {
        "id": "97aaad0f-ac66-410a-bf93-6786407a1f0e",
        "outputId": "ba909821-e84f-45af-fdc8-4caaf3910c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-win_amd64.whl.metadata (3.8 kB)\n",
            "Downloading pyenchant-3.2.2-py3-none-win_amd64.whl (11.9 MB)\n",
            "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/11.9 MB 325.1 kB/s eta 0:00:37\n",
            "   ---------------------------------------- 0.1/11.9 MB 651.6 kB/s eta 0:00:19\n",
            "    --------------------------------------- 0.2/11.9 MB 1.2 MB/s eta 0:00:10\n",
            "   - -------------------------------------- 0.4/11.9 MB 2.0 MB/s eta 0:00:06\n",
            "   - -------------------------------------- 0.6/11.9 MB 2.3 MB/s eta 0:00:05\n",
            "   -- ------------------------------------- 0.8/11.9 MB 2.7 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 1.0/11.9 MB 2.9 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 1.0/11.9 MB 2.9 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 1.0/11.9 MB 2.9 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 1.0/11.9 MB 2.9 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 1.6/11.9 MB 2.9 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 1.6/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 1.8/11.9 MB 2.9 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 2.0/11.9 MB 3.0 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 2.2/11.9 MB 3.0 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 2.2/11.9 MB 3.0 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 2.2/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 2.3/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 2.3/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 2.3/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 2.7/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 3.0/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 3.1/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 3.1/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 3.4/11.9 MB 2.8 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 3.5/11.9 MB 2.9 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 3.6/11.9 MB 2.8 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 3.7/11.9 MB 2.8 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 3.9/11.9 MB 2.8 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 3.9/11.9 MB 2.8 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 4.1/11.9 MB 2.8 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 4.2/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 4.3/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 4.4/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 4.5/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 4.6/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 4.8/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 4.8/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 5.0/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 5.1/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 5.2/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 5.3/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 5.4/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 5.6/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 5.7/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 5.8/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 5.9/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 6.0/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 6.2/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 6.3/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 6.4/11.9 MB 2.7 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 6.5/11.9 MB 2.6 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 6.6/11.9 MB 2.7 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 6.8/11.9 MB 2.7 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 6.9/11.9 MB 2.7 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 6.9/11.9 MB 2.7 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 7.0/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 7.0/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 7.1/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 7.2/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 7.4/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 7.5/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 7.6/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 7.8/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 7.9/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 8.1/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 8.2/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 8.2/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 8.4/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 8.5/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 8.6/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 8.7/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 8.7/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 8.9/11.9 MB 2.6 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 8.9/11.9 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 9.0/11.9 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 9.1/11.9 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 9.2/11.9 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 9.3/11.9 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 9.3/11.9 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 9.4/11.9 MB 2.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 9.5/11.9 MB 2.5 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.6/11.9 MB 2.5 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.6/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.7/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.8/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 9.9/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 10.0/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 10.1/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 10.2/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 10.3/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 10.3/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.4/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.5/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.5/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.6/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.7/11.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.7/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.8/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.9/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.9/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 11.0/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 11.1/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 11.1/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 11.2/11.9 MB 2.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 11.2/11.9 MB 2.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.3/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.4/11.9 MB 2.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.4/11.9 MB 2.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.5/11.9 MB 2.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.6/11.9 MB 2.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.6/11.9 MB 2.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.7/11.9 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.8/11.9 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.8/11.9 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.9/11.9 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.9/11.9 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.9/11.9 MB 2.1 MB/s eta 0:00:00\n",
            "Installing collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pyenchant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ff552b-e82b-4c27-a758-52c42e03c966",
      "metadata": {
        "id": "23ff552b-e82b-4c27-a758-52c42e03c966",
        "outputId": "46539202-eb04-4e26-aecc-3afbfbc4b9b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\adminsyma\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\adminsyma\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "import enchant\n",
        "from nltk.corpus import words\n",
        "from nltk import download\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "download('punkt')\n",
        "download('words')\n",
        "\n",
        "# Create an English dictionary for spell checking\n",
        "d = enchant.Dict(\"en_US\")\n",
        "english_words = set(words.words())\n",
        "\n",
        "# Function to check if a word is English or correct it if misspelled\n",
        "def check_or_correct_word(word):\n",
        "    if word.lower() in english_words:\n",
        "        return word\n",
        "    elif d.check(word):\n",
        "        return word\n",
        "    else:\n",
        "        suggestions = d.suggest(word)\n",
        "        if suggestions:\n",
        "            return suggestions[0]\n",
        "        else:\n",
        "            return word\n",
        "\n",
        "\n",
        "# Tokenize the cleaned text\n",
        "tokens = word_tokenize(cleaned_text)\n",
        "\n",
        "# Correct tokens and pair them with original tokens\n",
        "word_pairs = [(token, check_or_correct_word(token)) for token in tokens]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(word_pairs, columns=['Original Word', 'Corrected Word'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5bce23-eb6d-43d3-a09d-b5a378c1c60f",
      "metadata": {
        "id": "7f5bce23-eb6d-43d3-a09d-b5a378c1c60f",
        "outputId": "2f6f4ec9-9056-45a2-88cc-6dd92d94bed2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original Word</th>\n",
              "      <th>Corrected Word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>origina</td>\n",
              "      <td>origins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>dineniso</td>\n",
              "      <td>sordine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>rodpl</td>\n",
              "      <td>rod pl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>enorglo</td>\n",
              "      <td>Loren</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>e</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>din</td>\n",
              "      <td>din</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>eniso</td>\n",
              "      <td>venison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>vambiente</td>\n",
              "      <td>ambient</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>registered</td>\n",
              "      <td>registered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>rademark</td>\n",
              "      <td>trademark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>or</td>\n",
              "      <td>or</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>rofr</td>\n",
              "      <td>roar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>amek</td>\n",
              "      <td>make</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>darmstadt</td>\n",
              "      <td>Darmstadt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>glermony</td>\n",
              "      <td>Lermontov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>aeryliqua</td>\n",
              "      <td>reliquary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>contornte</td>\n",
              "      <td>contortion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>ecccadnd</td>\n",
              "      <td>Deccan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>panpc</td>\n",
              "      <td>panic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>bnlso</td>\n",
              "      <td>Olson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>oo</td>\n",
              "      <td>oo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>quality</td>\n",
              "      <td>quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>gcst</td>\n",
              "      <td>gest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>aaryllc</td>\n",
              "      <td>Amaryllis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>according</td>\n",
              "      <td>according</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>din</td>\n",
              "      <td>din</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>is</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>ocoi</td>\n",
              "      <td>coco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>encofsces</td>\n",
              "      <td>ensconces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>untatmatlona</td>\n",
              "      <td>uncontaminated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>curatral</td>\n",
              "      <td>curatorial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>kcmton</td>\n",
              "      <td>Moncton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>ujfi</td>\n",
              "      <td>Fuji</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>gtorag</td>\n",
              "      <td>ragtop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>rrohm</td>\n",
              "      <td>horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>plexiels</td>\n",
              "      <td>Plexiglas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>wx</td>\n",
              "      <td>ex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>plexiglogde</td>\n",
              "      <td>Plexiglas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>selar</td>\n",
              "      <td>sear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>id</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>vears</td>\n",
              "      <td>bears</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>usu</td>\n",
              "      <td>usu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>ne</td>\n",
              "      <td>ne</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>wegiv</td>\n",
              "      <td>wedgie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>eltowig</td>\n",
              "      <td>toweling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>der</td>\n",
              "      <td>der</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>ntd</td>\n",
              "      <td>std</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>moule</td>\n",
              "      <td>moule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>h</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>apis</td>\n",
              "      <td>Apis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>aoinuas</td>\n",
              "      <td>Antoninus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>isai</td>\n",
              "      <td>is ai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>jug</td>\n",
              "      <td>jug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>kol</td>\n",
              "      <td>kl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>hue</td>\n",
              "      <td>hue</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Original Word  Corrected Word\n",
              "266           the             the\n",
              "267       origina         origins\n",
              "268      dineniso         sordine\n",
              "269         rodpl          rod pl\n",
              "270       enorglo           Loren\n",
              "271             e               e\n",
              "272           din             din\n",
              "273         eniso         venison\n",
              "274     vambiente         ambient\n",
              "275    registered      registered\n",
              "276      rademark       trademark\n",
              "277            or              or\n",
              "278          rofr            roar\n",
              "279          amek            make\n",
              "280     darmstadt       Darmstadt\n",
              "281      glermony       Lermontov\n",
              "282     aeryliqua       reliquary\n",
              "283     contornte      contortion\n",
              "284      ecccadnd          Deccan\n",
              "285         panpc           panic\n",
              "286         bnlso           Olson\n",
              "287            oo              oo\n",
              "288       quality         quality\n",
              "289          gcst            gest\n",
              "290       aaryllc       Amaryllis\n",
              "291     according       according\n",
              "292            to              to\n",
              "293           din             din\n",
              "294            en              en\n",
              "295            is              is\n",
              "296          ocoi            coco\n",
              "297     encofsces       ensconces\n",
              "298  untatmatlona  uncontaminated\n",
              "299      curatral      curatorial\n",
              "300        kcmton         Moncton\n",
              "301          ujfi            Fuji\n",
              "302           and             and\n",
              "303        gtorag          ragtop\n",
              "304         rrohm          horror\n",
              "305      plexiels       Plexiglas\n",
              "306            wx              ex\n",
              "307   plexiglogde       Plexiglas\n",
              "308         selar            sear\n",
              "309            id              id\n",
              "310         vears           bears\n",
              "311           usu             usu\n",
              "312            ne              ne\n",
              "313         wegiv          wedgie\n",
              "314            no              no\n",
              "315       eltowig        toweling\n",
              "316           der             der\n",
              "317           ntd             std\n",
              "318         moule           moule\n",
              "319             h               h\n",
              "320          apis            Apis\n",
              "321       aoinuas       Antoninus\n",
              "322          isai           is ai\n",
              "323           jug             jug\n",
              "324           kol              kl\n",
              "325           hue             hue"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f06d89d5-a359-4a35-997d-6d300d630567",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "f06d89d5-a359-4a35-997d-6d300d630567"
      },
      "source": [
        "# Spacy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c32e2c-2148-4f2b-892f-2f7ebc312394",
      "metadata": {
        "id": "59c32e2c-2148-4f2b-892f-2f7ebc312394"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f12e30b-bf56-47ff-94cc-6599f91a301d",
      "metadata": {
        "id": "9f12e30b-bf56-47ff-94cc-6599f91a301d",
        "outputId": "ab1a30c4-cd40-46bc-c788-21a8d042aa9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "  Using cached spacy-3.7.5-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
            "Collecting spacy-hunspell\n",
            "  Using cached spacy_hunspell-0.1.0-py3-none-any.whl\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Using cached murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Using cached cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Using cached preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
            "  Using cached thinc-8.2.5-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Using cached srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
            "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
            "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Using cached langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
            "Collecting hunspell==0.5.0 (from spacy-hunspell)\n",
            "  Using cached hunspell-0.5.0.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Using cached language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
            "  Using cached blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
            "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Using cached cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
            "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Using cached marisa_trie-1.2.0-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adminsyma\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
            "Using cached spacy-3.7.5-cp311-cp311-win_amd64.whl (12.1 MB)\n",
            "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Using cached cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
            "Using cached langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
            "Using cached murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
            "Using cached preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
            "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Using cached srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
            "Using cached thinc-8.2.5-cp311-cp311-win_amd64.whl (1.5 MB)\n",
            "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "Using cached blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
            "Using cached cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
            "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Using cached language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached marisa_trie-1.2.0-cp311-cp311-win_amd64.whl (152 kB)\n",
            "Building wheels for collected packages: hunspell\n",
            "  Building wheel for hunspell (setup.py): started\n",
            "  Building wheel for hunspell (setup.py): finished with status 'error'\n",
            "  Running setup.py clean for hunspell\n",
            "Failed to build hunspell\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  python setup.py bdist_wheel did not run successfully.\n",
            "  exit code: 1\n",
            "  \n",
            "  [3 lines of output]\n",
            "  C:\\Users\\adminsyma\\anaconda3\\Lib\\site-packages\\setuptools\\_distutils\\extension.py:134: UserWarning: Unknown Extension options: 'compile_args', 'macros'\n",
            "    warnings.warn(msg)\n",
            "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
            "  [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for hunspell\n",
            "ERROR: Could not build wheels for hunspell, which is required to install pyproject.toml-based projects\n"
          ]
        }
      ],
      "source": [
        "pip install spacy spacy-hunspell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41eddd8d-fff5-4ffa-9707-89766eef9e90",
      "metadata": {
        "id": "41eddd8d-fff5-4ffa-9707-89766eef9e90",
        "outputId": "ba255da6-5e0c-421a-8a35-fcb4a91503d6"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'spacy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy_hunspell\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spaCyHunSpell\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load SpaCy model\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy_hunspell import spaCyHunSpell\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add Hunspell to SpaCy pipeline\n",
        "hunspell = spaCyHunSpell(nlp)\n",
        "nlp.add_pipe(hunspell)\n",
        "\n",
        "# Process text with SpaCy\n",
        "doc = nlp(cleaned_text)\n",
        "\n",
        "# Function to get correction suggestions\n",
        "def get_correction(word):\n",
        "    suggestions = word._.hunspell_spell\n",
        "    if suggestions:\n",
        "        return suggestions[0]\n",
        "    return word.text\n",
        "\n",
        "# Correct tokens and pair them with original tokens\n",
        "word_pairs = [(token.text, get_correction(token)) for token in doc]\n",
        "\n",
        "# Create a DataFrame\n",
        "df2 = pd.DataFrame(word_pairs, columns=['Original Word', 'Corrected Word'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10abaca2-7558-4e63-a376-a3a9e052f3e4",
      "metadata": {
        "id": "10abaca2-7558-4e63-a376-a3a9e052f3e4"
      },
      "source": [
        "# Merged Functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7711ca53-613b-4837-8a50-3524e3c814e3",
      "metadata": {
        "id": "7711ca53-613b-4837-8a50-3524e3c814e3",
        "outputId": "c8e0f5d7-0be0-480b-f2e0-9d97ccbb84a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most occurring word: Plexiglas\n"
          ]
        }
      ],
      "source": [
        "# Drop rows where 'Corrected Word' is shorter than 3 characters\n",
        "df = df[df['Corrected Word'].str.len() >= 3]\n",
        "\n",
        "# Now find the most occurring word\n",
        "word_counts = df['Corrected Word'].value_counts()\n",
        "most_occuring_word = word_counts.idxmax()\n",
        "\n",
        "print(\"Most occurring word:\", most_occuring_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f56f0af0-0ba6-4b88-b191-38b99992d22a",
      "metadata": {
        "id": "f56f0af0-0ba6-4b88-b191-38b99992d22a",
        "outputId": "cbad660f-1e6d-4e5c-d3e1-e03e77b97ca5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\adminsyma\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\adminsyma\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "import enchant\n",
        "from nltk.corpus import words\n",
        "from nltk import download\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "download('punkt')\n",
        "download('words')\n",
        "\n",
        "# Create an English dictionary for spell checking\n",
        "d = enchant.Dict(\"en_US\")\n",
        "english_words = set(words.words())\n",
        "\n",
        "def clean_and_find_most_occuring_word(results_df, row_index):\n",
        "    # Filter for rows where 'ID' matches the given row_index and select the 'text' column\n",
        "    text = results_df[results_df['ID'] == row_index]['text'].values\n",
        "\n",
        "    # Convert bytes-like object to string (assuming UTF-8 encoding)\n",
        "    text_str = text[0].decode('utf-8') if isinstance(text[0], bytes) else text[0]\n",
        "\n",
        "    # Clean the text\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text_str)  # Remove special characters, digits, and punctuation\n",
        "    cleaned_text = cleaned_text.lower()  # Convert to lowercase\n",
        "    cleaned_text = ' '.join(cleaned_text.split())  # Remove extra whitespace\n",
        "\n",
        "    # Tokenize the cleaned text\n",
        "    tokens = word_tokenize(cleaned_text)\n",
        "\n",
        "    # Function to check if a word is English or correct it if misspelled\n",
        "    def check_or_correct_word(word):\n",
        "        if word.lower() in english_words:\n",
        "            return word\n",
        "        elif d.check(word):\n",
        "            return word\n",
        "        else:\n",
        "            suggestions = d.suggest(word)\n",
        "            if suggestions:\n",
        "                return suggestions[0]\n",
        "            else:\n",
        "                return word\n",
        "\n",
        "    # Correct tokens and pair them with original tokens\n",
        "    word_pairs = [(token, (token)) for token in tokens]\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(word_pairs, columns=['Original Word', 'Corrected Word'])\n",
        "\n",
        "    # Drop rows where 'Corrected Word' is shorter than 3 characters\n",
        "    df = df[df['Corrected Word'].str.len() >= 4]\n",
        "\n",
        "    # Find the most occurring word\n",
        "    if not df.empty:\n",
        "        word_counts = df['Corrected Word'].value_counts()\n",
        "        most_occuring_word = word_counts.idxmax()\n",
        "        return most_occuring_word\n",
        "    else:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41c0487-0755-4636-87a6-97f50054c12f",
      "metadata": {
        "id": "c41c0487-0755-4636-87a6-97f50054c12f",
        "outputId": "5abbd475-b41b-4430-9c0a-d7e44a50ae48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most occurring word for ID 0: kemmler\n",
            "No valid words found after processing for ID 2.\n",
            "Most occurring word for ID 3: plexiglas\n",
            "No valid words found after processing for ID 4.\n",
            "No valid words found after processing for ID 5.\n",
            "No valid words found after processing for ID 7.\n",
            "Most occurring word for ID 8: etelene\n",
            "Most occurring word for ID 15: vears\n",
            "No valid words found after processing for ID 16.\n",
            "Most occurring word for ID 17: klelide\n",
            "Most occurring word for ID 19: xaye\n",
            "Most occurring word for ID 20: registered\n",
            "Most occurring word for ID 21: aaskin\n",
            "Most occurring word for ID 23: plexiglas\n",
            "Most occurring word for ID 24: oohd\n",
            "No valid words found after processing for ID 25.\n",
            "Most occurring word for ID 27: ledi\n",
            "No valid words found after processing for ID 28.\n",
            "Most occurring word for ID 29: krole\n",
            "Most occurring word for ID 30: exolon\n",
            "Most occurring word for ID 31: rgmictic\n",
            "Most occurring word for ID 32: exolon\n",
            "No valid words found after processing for ID 33.\n",
            "Most occurring word for ID 34: icask\n",
            "No valid words found after processing for ID 36.\n",
            "Most occurring word for ID 40: pleh\n",
            "Most occurring word for ID 41: made\n",
            "Most occurring word for ID 42: made\n",
            "Most occurring word for ID 43: polycarbonate\n",
            "Most occurring word for ID 47: sjalh\n",
            "No valid words found after processing for ID 48.\n",
            "Most occurring word for ID 50: petg\n",
            "Most occurring word for ID 52: ytsan\n",
            "Most occurring word for ID 53: nisx\n",
            "Most occurring word for ID 54: pexk\n",
            "No valid words found after processing for ID 55.\n",
            "No valid words found after processing for ID 56.\n",
            "No valid words found after processing for ID 57.\n",
            "Most occurring word for ID 58: transparent\n",
            "No valid words found after processing for ID 59.\n",
            "Most occurring word for ID 60: mors\n",
            "No valid words found after processing for ID 63.\n",
            "Most occurring word for ID 64: komnahmm\n",
            "Most occurring word for ID 65: aourub\n",
            "Most occurring word for ID 66: rohm\n",
            "Most occurring word for ID 69: ifaa\n",
            "Most occurring word for ID 75: face\n",
            "No valid words found after processing for ID 79.\n",
            "Most occurring word for ID 84: tntt\n",
            "Most occurring word for ID 87: perspex\n",
            "Most occurring word for ID 89: svidlxjid\n",
            "Most occurring word for ID 92: qddt\n",
            "Most occurring word for ID 94: service\n",
            "Most occurring word for ID 96: htne\n",
            "No valid words found after processing for ID 97.\n",
            "Most occurring word for ID 100: hles\n",
            "Most occurring word for ID 101: asking\n",
            "Most occurring word for ID 102: niniq\n",
            "Most occurring word for ID 103: plli\n",
            "Most occurring word for ID 104: bfexic\n",
            "Most occurring word for ID 113: rogisterde\n",
            "Most occurring word for ID 114: plexic\n",
            "No valid words found after processing for ID 115.\n",
            "Most occurring word for ID 116: vgls\n",
            "Most occurring word for ID 121: decfyz\n",
            "Most occurring word for ID 125: zajoixekd\n",
            "Most occurring word for ID 126: zajbxehe\n",
            "Most occurring word for ID 135: ymna\n",
            "Most occurring word for ID 136: decl\n",
            "Most occurring word for ID 137: zeogec\n",
            "Most occurring word for ID 142: whoe\n",
            "Most occurring word for ID 144: kagla\n",
            "Most occurring word for ID 145: katta\n",
            "Most occurring word for ID 147: biarnds\n",
            "Most occurring word for ID 170: rohm\n",
            "Most occurring word for ID 171: mamm\n",
            "Most occurring word for ID 174: eglas\n",
            "Most occurring word for ID 177: hnetttetentemene\n",
            "Most occurring word for ID 183: service\n",
            "Most occurring word for ID 189: zaiaaf\n",
            "No valid words found after processing for ID 205.\n",
            "Most occurring word for ID 211: ekploe\n",
            "Most occurring word for ID 212: aooo\n",
            "Most occurring word for ID 213: lfpiera\n",
            "Most occurring word for ID 214: jervice\n",
            "Most occurring word for ID 216: baboh\n",
            "Most occurring word for ID 222: aujpno\n",
            "Most occurring word for ID 223: qjujwu\n",
            "No valid words found after processing for ID 224.\n",
            "Most occurring word for ID 227: aeefulno\n",
            "Most occurring word for ID 228: kenenemntet\n",
            "Most occurring word for ID 235: perspex\n",
            "Most occurring word for ID 236: jepen\n",
            "No valid words found after processing for ID 240.\n",
            "No valid words found after processing for ID 242.\n",
            "Most occurring word for ID 244: perspex\n",
            "Most occurring word for ID 245: perspex\n",
            "Most occurring word for ID 246: perspex\n",
            "Most occurring word for ID 252: perspex\n",
            "Most occurring word for ID 256: mdee\n",
            "Most occurring word for ID 261: asdd\n",
            "Most occurring word for ID 262: rspex\n",
            "Most occurring word for ID 277: acri\n",
            "Most occurring word for ID 278: sheet\n",
            "Most occurring word for ID 279: sfrt\n",
            "Most occurring word for ID 281: perspex\n",
            "Most occurring word for ID 282: perspex\n",
            "Most occurring word for ID 288: hade\n",
            "Most occurring word for ID 289: epis\n",
            "Most occurring word for ID 292: plexiglrs\n",
            "Most occurring word for ID 293: sohnn\n",
            "Most occurring word for ID 294: epis\n",
            "Most occurring word for ID 296: uaup\n",
            "Most occurring word for ID 299: viexgls\n",
            "Most occurring word for ID 311: qelaetee\n",
            "No valid words found after processing for ID 313.\n",
            "Most occurring word for ID 314: bhobhi\n",
            "Most occurring word for ID 320: svnaaa\n",
            "Most occurring word for ID 321: obisinal\n",
            "Most occurring word for ID 324: ocpv\n",
            "Most occurring word for ID 325: poulailshiiso\n",
            "Most occurring word for ID 326: apis\n",
            "Most occurring word for ID 328: pleeiciso\n",
            "Most occurring word for ID 331: perspex\n",
            "Most occurring word for ID 332: perspes\n",
            "No valid words found after processing for ID 339.\n",
            "No valid words found after processing for ID 341.\n",
            "Most occurring word for ID 346: heipker\n",
            "Most occurring word for ID 347: letroe\n",
            "Most occurring word for ID 352: pvvc\n",
            "No valid words found after processing for ID 353.\n",
            "No valid words found after processing for ID 354.\n",
            "No valid words found after processing for ID 355.\n",
            "Most occurring word for ID 357: oooc\n",
            "Most occurring word for ID 358: sooc\n",
            "Most occurring word for ID 359: oooq\n",
            "Most occurring word for ID 360: peald\n",
            "No valid words found after processing for ID 361.\n",
            "Most occurring word for ID 362: pniboat\n",
            "Most occurring word for ID 363: epis\n",
            "Most occurring word for ID 367: noijomotni\n",
            "Most occurring word for ID 369: hanaleen\n",
            "Most occurring word for ID 371: jcat\n",
            "No valid words found after processing for ID 373.\n",
            "Most occurring word for ID 376: llas\n",
            "Most occurring word for ID 377: btea\n",
            "Most occurring word for ID 378: peea\n",
            "Most occurring word for ID 381: inasking\n",
            "Most occurring word for ID 383: sisxs\n",
            "Most occurring word for ID 386: gtnpvnon\n",
            "Most occurring word for ID 387: eskiing\n",
            "Most occurring word for ID 390: buixsew\n",
            "No valid words found after processing for ID 394.\n",
            "Most occurring word for ID 397: duipuadop\n",
            "Most occurring word for ID 400: derlas\n",
            "Most occurring word for ID 432: maks\n",
            "Most occurring word for ID 433: sheet\n",
            "Most occurring word for ID 434: sdbxeidmaia\n",
            "Most occurring word for ID 435: whqd\n",
            "Most occurring word for ID 436: plexige\n",
            "Most occurring word for ID 437: plexiglas\n",
            "Most occurring word for ID 438: lnet\n",
            "Most occurring word for ID 449: plexiglas\n",
            "No valid words found after processing for ID 453.\n",
            "Most occurring word for ID 454: bupxset\n",
            "Most occurring word for ID 455: pror\n",
            "Most occurring word for ID 462: dccgiqiua\n",
            "No valid words found after processing for ID 465.\n",
            "No valid words found after processing for ID 468.\n",
            "Most occurring word for ID 469: immmeef\n",
            "Most occurring word for ID 471: tntt\n",
            "Most occurring word for ID 472: ttttt\n",
            "Most occurring word for ID 473: tttt\n",
            "Most occurring word for ID 480: ahaefennnnrhtenefe\n",
            "Most occurring word for ID 481: side\n",
            "Most occurring word for ID 482: dkahu\n",
            "Most occurring word for ID 489: ferbt\n",
            "No valid words found after processing for ID 502.\n",
            "No valid words found after processing for ID 503.\n",
            "No valid words found after processing for ID 504.\n",
            "No valid words found after processing for ID 505.\n",
            "No valid words found after processing for ID 506.\n",
            "Most occurring word for ID 528: quarq\n",
            "Most occurring word for ID 532: oieii\n",
            "Most occurring word for ID 543: cast\n",
            "Most occurring word for ID 544: cast\n",
            "Most occurring word for ID 557: hnove\n",
            "Most occurring word for ID 558: cast\n",
            "Most occurring word for ID 559: green\n",
            "Most occurring word for ID 560: cast\n",
            "Most occurring word for ID 570: cast\n",
            "Most occurring word for ID 572: jsej\n",
            "Most occurring word for ID 574: perspex\n",
            "Most occurring word for ID 579: perspex\n",
            "Most occurring word for ID 580: perspex\n",
            "Most occurring word for ID 581: perspex\n",
            "Most occurring word for ID 584: aetatpeitude\n",
            "Most occurring word for ID 594: ajdix\n",
            "No valid words found after processing for ID 595.\n",
            "Most occurring word for ID 600: jsecv\n",
            "Most occurring word for ID 601: nacast\n",
            "Most occurring word for ID 602: perspex\n",
            "Most occurring word for ID 603: perspex\n",
            "Most occurring word for ID 606: lxexadsdld\n",
            "Most occurring word for ID 608: caja\n",
            "No valid words found after processing for ID 609.\n",
            "No valid words found after processing for ID 612.\n",
            "Most occurring word for ID 615: loop\n",
            "Most occurring word for ID 616: perspex\n",
            "Most occurring word for ID 621: vwwd\n",
            "Most occurring word for ID 622: ioopl\n",
            "Most occurring word for ID 623: obenaite\n",
            "Most occurring word for ID 627: perspex\n",
            "Most occurring word for ID 628: perspex\n",
            "Most occurring word for ID 632: loopl\n",
            "Most occurring word for ID 633: iooti\n",
            "Most occurring word for ID 634: lool\n",
            "Most occurring word for ID 635: supen\n",
            "Most occurring word for ID 639: japem\n",
            "Most occurring word for ID 642: perspex\n",
            "Most occurring word for ID 653: perspex\n",
            "Most occurring word for ID 654: cast\n",
            "Most occurring word for ID 655: cast\n",
            "Most occurring word for ID 656: perspex\n",
            "Most occurring word for ID 657: guarantee\n",
            "Most occurring word for ID 658: registered\n",
            "Most occurring word for ID 659: perspex\n",
            "Most occurring word for ID 664: rohm\n",
            "Most occurring word for ID 665: rpide\n",
            "Most occurring word for ID 666: piex\n",
            "Most occurring word for ID 669: ccconfef\n",
            "Most occurring word for ID 670: nglas\n",
            "Most occurring word for ID 671: whoei\n",
            "Most occurring word for ID 672: befd\n",
            "Most occurring word for ID 673: alerndtne\n",
            "Most occurring word for ID 674: veenend\n",
            "Most occurring word for ID 675: loncinieed\n",
            "Most occurring word for ID 680: perspex\n",
            "Most occurring word for ID 683: perspex\n",
            "Most occurring word for ID 684: perspex\n",
            "Most occurring word for ID 685: perspex\n",
            "Most occurring word for ID 686: cast\n",
            "No valid words found after processing for ID 697.\n",
            "Most occurring word for ID 723: guarantee\n",
            "Most occurring word for ID 724: sani\n",
            "Most occurring word for ID 728: eenn\n",
            "No valid words found after processing for ID 733.\n",
            "Most occurring word for ID 734: plexiq\n",
            "Most occurring word for ID 738: tmni\n",
            "Most occurring word for ID 754: ilas\n",
            "No valid words found after processing for ID 755.\n",
            "No valid words found after processing for ID 761.\n",
            "Most occurring word for ID 762: eman\n",
            "Most occurring word for ID 777: pooc\n",
            "No valid words found after processing for ID 778.\n",
            "Most occurring word for ID 780: egees\n",
            "Most occurring word for ID 781: tqueg\n",
            "Most occurring word for ID 782: ooooz\n",
            "No valid words found after processing for ID 801.\n",
            "Most occurring word for ID 802: service\n",
            "Most occurring word for ID 803: glasde\n",
            "No valid words found after processing for ID 809.\n",
            "No valid words found after processing for ID 816.\n",
            "Most occurring word for ID 819: ebjersaive\n",
            "Most occurring word for ID 820: perspex\n",
            "No valid words found after processing for ID 821.\n",
            "Most occurring word for ID 826: plexiglas\n",
            "Most occurring word for ID 827: plexie\n",
            "Most occurring word for ID 828: suantlamunafolons\n",
            "Most occurring word for ID 829: kkarla\n",
            "Most occurring word for ID 836: plexiglas\n",
            "Most occurring word for ID 837: fnel\n",
            "Most occurring word for ID 838: protectora\n",
            "Most occurring word for ID 840: daree\n",
            "No valid words found after processing for ID 841.\n",
            "Most occurring word for ID 842: llol\n",
            "Most occurring word for ID 843: senvice\n",
            "Most occurring word for ID 844: guarantee\n",
            "Most occurring word for ID 845: registered\n",
            "Most occurring word for ID 846: perspex\n",
            "Most occurring word for ID 847: rohm\n",
            "Most occurring word for ID 848: rohm\n",
            "Most occurring word for ID 850: masking\n",
            "Most occurring word for ID 851: eyiglase\n",
            "Most occurring word for ID 852: oido\n",
            "Most occurring word for ID 854: piajas\n",
            "Most occurring word for ID 855: sinnic\n",
            "Most occurring word for ID 857: perspex\n",
            "Most occurring word for ID 861: looe\n",
            "Most occurring word for ID 866: neclac\n",
            "Most occurring word for ID 867: perspex\n",
            "Most occurring word for ID 875: aajq\n",
            "Most occurring word for ID 902: stntl\n",
            "Most occurring word for ID 908: pnwani\n",
            "No valid words found after processing for ID 916.\n",
            "Most occurring word for ID 917: majoixak\n",
            "Most occurring word for ID 918: slie\n",
            "Most occurring word for ID 921: perspex\n",
            "No valid words found after processing for ID 927.\n",
            "Most occurring word for ID 929: enie\n",
            "Most occurring word for ID 930: aatie\n",
            "Most occurring word for ID 931: eeaa\n",
            "Most occurring word for ID 932: plaas\n",
            "Most occurring word for ID 933: tecos\n",
            "Most occurring word for ID 934: perspex\n",
            "Most occurring word for ID 937: aaaa\n",
            "Most occurring word for ID 972: service\n",
            "No valid words found after processing for ID 985.\n",
            "Most occurring word for ID 986: oricr\n",
            "Most occurring word for ID 989: ebcv\n",
            "Most occurring word for ID 999: eltauere\n",
            "Most occurring word for ID 1013: mugv\n",
            "Most occurring word for ID 1015: pdeet\n",
            "Most occurring word for ID 1016: dceot\n",
            "Most occurring word for ID 1017: perspex\n",
            "Most occurring word for ID 1018: aletoiae\n",
            "Most occurring word for ID 1019: laehnle\n",
            "Most occurring word for ID 1030: koedaleo\n",
            "Most occurring word for ID 1037: jiceede\n",
            "Most occurring word for ID 1038: aaee\n",
            "Most occurring word for ID 1039: fvice\n",
            "No valid words found after processing for ID 1050.\n",
            "No valid words found after processing for ID 1057.\n",
            "Most occurring word for ID 1058: brexigfh\n",
            "Most occurring word for ID 1065: mncale\n",
            "Most occurring word for ID 1066: rohm\n",
            "Most occurring word for ID 1068: eaelelte\n",
            "Most occurring word for ID 1069: aski\n",
            "Most occurring word for ID 1071: tantleerat\n",
            "Most occurring word for ID 1072: here\n",
            "Most occurring word for ID 1077: jhuu\n",
            "Most occurring word for ID 1098: luusy\n",
            "Most occurring word for ID 1100: qnanhun\n"
          ]
        }
      ],
      "source": [
        "# Loop over each index and print the most occurring word\n",
        "for index_to_process in results_df['ID']:\n",
        "    most_occuring_word = clean_and_find_most_occuring_word(results_df, index_to_process)\n",
        "\n",
        "    if most_occuring_word:\n",
        "        print(f\"Most occurring word for ID {index_to_process}: {most_occuring_word}\")\n",
        "    else:\n",
        "        print(f\"No valid words found after processing for ID {index_to_process}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37c6ba9-2a1c-49d7-9460-ce5de7da7954",
      "metadata": {
        "id": "f37c6ba9-2a1c-49d7-9460-ce5de7da7954",
        "outputId": "a9e3eb42-85f9-47d7-bcf1-95c7f60f7cc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Service Side apis 93i448 , <dll eneet [GLASe EPDE Ivirarengdkena uat BYAROHM PMMA masking DINEN IS0 *orJi(eni rgla) latnone /5077828 3o 7023 Aoeitye onnien Gir Fla Nel WwwF\" Nglasde PELD; oimjricn; WWWplexigias de Pp Y0 b1x0 #MMm D} Quclo ar-34 Hne fere SScan EZoLos A(0i6 \\' ICJO OSiNJNiQ Z-EzeLoci #LJou fnntd \" < \\' bupsetu YWW : WHOd Ad) Ol^ {\" - ~` . EUao t ddzi u_lS Sy7bi  ,. .'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df[results_df['ID'] == 94]['text'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32d1450-2459-46e1-a878-c0a0d8bd05ab",
      "metadata": {
        "id": "d32d1450-2459-46e1-a878-c0a0d8bd05ab"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}